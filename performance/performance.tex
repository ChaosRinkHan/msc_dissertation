\chapter{Performance experiments}

The performance experiments were designed to explore the parallel performance of ABC SMC inference framework that was used in our parameter estimation and model selection tasks. Generally, ABC SMC is a time-consuming and computation-intensive task and ideally executed on large clusters. The scheduling strategy, implementation details, randomness in the algorithm and many other factors can affect the parallel efficiency. Thus, we designed a scaling-up experiment and studied a case where abnormal performance was observed.

% [MORE meanings of the performance study]

\section{Scaling-up}

First experiments are designed to illustrate the scaling-up performance. The program used here is an implementation of ABC SMC on model 5. The details of the ABC SMC settings are listed below

\begin{itemize}
    \item Prior distribution: default to log-uniform distribution [$1\times 10^{-6}$, 50] for all the 12 parameters
    \item threshold schedule: median epsilon
    \item No factors, no adaptive distance or adaptive population applied
    \item Population size is 2000, with 20 generations
\end{itemize}

% [HOW PYABC parallelise the sampling]

For HPC systems like Cirrus, \verb|pyabc| uses \verb|multiprocessing| for multi-core parallel sampling. By default, if the number of cores is not specified, it will automatically read the number of available cores and use them all. Cirrus has a 36-core CPU which supports hyperthreading, such that the maximal number of cores available to \verb|multiprocessing| is 72.

The experiment was executed on Cirrus, using 8, 16, 24, 36, 54 and 72 cores respectively. Each run was repeated ten times. The average execution time and required number of samples are recorded. Hyperthreading was enabled when using 54 and 72 cores. The access to the node that contains computation cores is exclusive, such that the execution would not be affected by other programs of operations.

The implementation of ABC SMC in \verb|pyabc| enables the parallelisation of sampling process, which is the most time-consuming part. The rest part of the program is mostly not parallelised, e.g. database I/O and reductions operations. The sampling process involves sampling, perturbation and test of the acceptance criteria, which are computation-intensive.

In practice, using ABC SMC to estimate the parameters of a given model could cost up to several hundred of hours if the computational resources are limited \cite{ref:compare}. The performance experiment result could provide a reference that illustrates how the efficiency changes when scaling-up or the trade-offs in computational resources' cost and their benefit.

\subsubsection{Results}

% [scaling-up performance: speed-up and efficiency]

% [large variation in required sampling numbers]

% [possible reasons]

\begin{figure}[h]
    \begin{center}
        \resizebox{1.0\hsize}{!}{\includegraphics{fig/speedup.png}}
    \end{center}

    \caption[Speedup of the program]{Speedup of the program. Line in orange indicates the ideal linear speedup}
    \label{fig:speedup}
\end{figure}

The recorded execution time under different numbers of cores was used to calculate the speedup of the program (Figure \ref{fig:speedup}). Here 8-core run is regarded as the baseline for speedup and efficiency, as the serial version (using only one core) can take quite a long time to finish 10 repeats. When increasing number of cores, the execution time drops fast at first, but the decreasing trend became slower for large numbers of cores; 36, 54 and 72 cores gives nearly the same average execution time and consequently gains very close speedup values (Table \ref{table:performance}).

\begin{table}[H]
    \centering
    \begin{tabular}{|c c c c c|}
        \hline
        Number of cores & Avg. time (second) & Avg. sample size & Speedup & Efficiency \\ [0.5ex]
        \hline\hline
        8               & 6617          & 445406.8              & 1       & 1          \\
        16              & 3926          & 590221.0              & 1.61    & 0.807      \\
        24              & 2921          & 573339.8              & 2.17    & 0.723      \\
        36              & 2096          & 446948.7              & 3.02    & 0.672      \\
        54              & 2076          & 640404.9              & 3.05    & 0.452      \\
        72              & 2071          & 768096.0              & 3.06    & 0.340      \\
        \hline
    \end{tabular}
    \caption{Performance data}
    \label{table:performance}
\end{table}

Denote the number of cores used in the ABC SMC runs as variable $p$. The speedup curve shows a linear trend when $p\leq 36$; when $p\geq 36$ the speedup stays nearly unchanged. $p=36$ is an inflexion point, where 36 is the maximum numbers available physical cores in a compute node of Cirrus. A constant drop of efficiency is observed when increasing $p$; smaller $p$ ($p<36$) gives an efficiency higher than 65\% but greater $p$ e.g. $p=72$ results in a low efficiency (34\%).

% \begin{figure}[h]
%     \begin{center}
%         \resizebox{1.0\hsize}{!}{\includegraphics{fig/sample_per_time.png}}
%     \end{center}

%     \caption[Average samples in a second, under different number of cores]{Average samples in one second, under different number of cores}
%     \label{fig:sample_per_sec}
% \end{figure}

\section{Discussions}

A high variance of total required number of samples was observed in the scaling-up experiments: some single runs required much more samples to finish 20 populations, where they were supposed to have relatively similar average required samples such that we can compare the performance directly via speedup or efficiency. 

The variant total required number of samples drawn our attention to the per-second performance. Although the execution time was not improved by using 54 or 72 cores, the required number of samples were higher than that of $p=36$, which indicates slight improvements. However, the high variance made us hard to gave statistically significant conclusions on the per-second performance.

% our interests switched to the per-second performance, where the average sampling numbers per second under different of numbers of cores ($p$) are plotted (Figure \ref{fig:sample_per_sec}). The plot shows that even theoretical speedup stops growing when $p>36$, the average sampling numbers per second performance still get improved when using more than 36 cores. It proves that the implementation used here scales reasonably well without encountering bottleneck when using multi-core parallelisation inside one physical node.

The variant total required number of samples for different runs under the same setting was most likely the result of different threshold evolve path. Median epsilon schedule and randomness in the sampling process resulted in different sequences of thresholds for different runs, which means different repeated runs may have different convergency path \cite{threshold}. For example, Some runs temporarily converge to a local optimum, while the target epsilon in the next generation cannot possibly be reached if the new particles are still concentrated in the local optimum. In this case, a huge amount of sample will be drawn to find enough accepted particles, and the new generation will be able to jump out of the local optimum and have different concentrations. 

\begin{figure}[ht!]
    \begin{center}
        \resizebox{1.0\hsize}{!}{\includegraphics{fig/local_modes_new.png}}
    \end{center}

    \caption[Local optimum and abnormal pattern]{(a) Required number of samples for two example runs (A and B). Different colour represents different generation (from bottom to top: generation 1 to generation 20). Run A took huge amount of time in population 11. (b) Execution time for each generation of Run A. (c) Scatter plot of required number of samples against execution time for each generation. Generation 1 and two outliers, i.e. generation 11 and generation 2, are marked in different colours from other generations}
    \label{fig:local_modes}
\end{figure}

To illustrate this, Two independent run, namely Run A and Run B, were chosen from the experiment of $p=24$ and visualised in Figure \ref{fig:local_modes} and Figure \ref{fig:local_para}. These two runs used identical options for the algorithm and implementation. Figure \ref{fig:local_modes} (a) shows the comparison of the required number of samples, where Run A converged to a local mode. In population 11 Run A took much more sample tires to move away from the local optimum. Figure \ref{fig:local_para} compares the posterior density distribution before (t=9, cyan) and after (t=13, red) the concentration jumping: significant movement of concentrations in posterior density distributions are observed, especially in parameters from ODE 1, 2 and 4. An interning movement is that there are two concentrations in $\kappa_{\Phi\beta}$ and $\mu_\Phi$ when t=9, and the majority of particles are concentrated in the second concentration with higher values; when t=13, the second concentration distribution disappears and all particles are concentrated near zero.

\begin{figure}[ht!]
    \begin{center}
        \resizebox{1.0\hsize}{!}{\includegraphics{fig/local_para.png}}
    \end{center}

    \caption[Parameter density distribution before and after the concentration movement in generation 11]{Parameter density distribution before (generation 9, cyan) and after (generation 13, red) the concentration movement in generation 11}
    \label{fig:local_para}
\end{figure}

Moreover, we found that the execution time was not ideally proportional to the sampling tires in that period of time, for both different repeated runs and different generations in a single run. From the same example, the sample size for each generation of Run A (Figure \ref{fig:local_modes} (a)) is not proportional to its execution time (Figure \ref{fig:local_modes} (b)), especially for the first two generations and generation 11. Figure \ref{fig:local_modes} (c) shows a scatter plot of the required samples and execution time for each generation, where two obvious outliers (generation 1 and generation 11) are observed.

% Figure \ref{fig:local_modes} (b) and (c) show the non-linear relationship between execution time and sample tries in different generations. 

% Apart from 1st and 2nd generation, generation 3 to 20 show a general linear relationship i.e. $T_t\propto n_t$, where $t$ is the population index, $T_t$ is the execution time of generation $t$ and $n_t$ is the required samples in generation $t$.

% However, this relationship does not hold for the first two generations. 

Generation 1 (red pont in Figure \ref{fig:local_modes} (c)) drew samples from prior, but it was done with high efficiency as only a small amount of time are taken; generation 2 (purple pont in Figure \ref{fig:local_modes} (c)) took an unusually large amount of the while it did not require much more samples. The abnormal execution time of generation 1 and 2 were observed in all other runs, where for $p=24$ generation 1 usually takes c. 16s and generation 2 takes c. 1600s. This is believed to be related to the initialisation of the algorithm. For local modes, e.g. generation 11 (green pont in Figure \ref{fig:local_modes} (c)), high efficiency were achieved.

By looking into the code, some reasons can be found. There exist some `cheap' particles. If at the first time points, a variable reached unacceptably high value (regarded as \verb|Inf| in \verb|Python|), the ODE solver cannot perform further integration but result in the simulated data full of \verb|NaN|s. Such particles cost less time than a usual particle (where values at 120 data points are explicitly calculated and then compared with observed data). Local mode, e.g. generation 11, might take a large amount of these `cheap' particles, thus it is `efficient' regarding the per-second performance. Also, generation 1 draws samples directly from prior without fitting and using kernels, so it is much faster. The huge amount of time observed in generation 2 is believed to be a result of some initialisation steps in the ABC SMC algorithm.

To conclude, the performance experiments revealed reasonable scaling-up behaviour when the \verb|Python| processes did not exceed the number of physical cores. Local modes lead to high variance in total required number of samples, and the relationship between required number of sample numbers and required execution time are not ideally linear; they all made further detailed analysis difficult.

Additionally, by observing CPU frequency and load curve in-time while running the program, we found that the parallelised part is limited to the sampling, calculation and criterion test process. Some reduction calculations and preparation work for the next generation (e.g. calculation of the new epsilon values, normalisation of data, fit of multivariate kernel) are serial. The database I/O is also serial.  It is noticed that the program takes no advantage of graphics card, as \verb|multiprocessing| along can only exploit the resources inside CPU. 

% A possible explain to these phenomenons can be that the median epsilon schedule results in different threshold strategies due to the randomness in the sampling process, thus results in different approximate convergency paths for different runs. Some runs that are stuck in a local optimum and require smaller target epsilon will take huge amount of samples to move away from the local optimum. This have been observed when the distribution of posterior is plotted before and after jumping away from local modes (FIGURE and more explain). Also, time spent in each sample using sanme number of cores is not constant in our case, which might be a result of the parallel schedule; ideally a serial run using only one core will see a nearly constant time spent in every particle.



% \section{Profiling}

% The performance could also be analysed given a profiling report. The second experiment profiles the program to reveal the detailed time consumption for each operation and the possible bottleneck, according to which we could find the hot-spot of program and given possible suggestions on improving the performance.

% In this case, profile tools \verb|cProfile| and \verb|yappi| is used in PyCharm IDE.

% \subsubsection{Results}

% [profiling results: hot-spot and possible improvements]
